{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport scipy.signal as signal\nimport matplotlib.pyplot as plt\nimport pywt\nimport os\nimport re\nfrom scipy.signal import butter, filtfilt\n\ndef calculate_psd_features(file_path):\n    with open(file_path, \"r\") as file:\n        signal_data = file.readlines()\n        signal_data = [float(data_point) for data_point in signal_data]\n\n        # Apply bandpass filter\n        lowcut = 0.5\n        highcut = 20\n        signal_data = apply_bandpass_filter(signal_data, lowcut, highcut)\n\n        # Calculate PSD\n        f, psd = signal.welch(signal_data, fs=50, nperseg=1024)\n\n        # Extract features from PSD\n         \n        var_psd = np.var(psd)\n        mean_psd = np.mean(psd)\n        std_psd = np.std(psd)\n        energy_psd = np.sum(psd)\n\n        return   var_psd, mean_psd, std_psd, energy_psd\n\ndef apply_bandpass_filter(signal_data, lowcut, highcut, fs=50, order=5 ):\n    # Design the bandpass filter\n    nyquist_freq = 0.5 * fs\n    low = lowcut / nyquist_freq\n    high = highcut / nyquist_freq\n    b, a = butter(4, [low, high], btype=\"band\")\n\n    # Apply the filter to the signal\n    filtered_signal = filtfilt(b, a, signal_data)\n    return filtered_signal\n\ndirectory = \"/kaggle/input/data-eog-last-v/3-class\"\nfiles = os.listdir(directory)\n\n# Sort the file names in ascending order\nsorted_files = sorted(files)\n\npsd_features_list = []\n\nfor file_name in sorted_files:\n    if file_name.endswith(\".txt\"):\n        file_path = os.path.join(directory, file_name)\n        var_psd, mean_psd, std_psd, energy_psd = calculate_psd_features(file_path)\n        std_psd=round(std_psd, 3)\n         \n        var_psd=round(var_psd, 3)\n        mean_psd=round(mean_psd, 3)\n        energy_psd=round(energy_psd, 3)\n        label = re.split(r\"\\d\", file_name, 1)[0]\n        psd_features_list.append(( var_psd, mean_psd, std_psd, energy_psd, label))\nprint(\"done\") ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfeatures_psd = []\n\nfor i in range(0, 200, 2):\n    row = psd_features_list[i] + psd_features_list[i+1]\n    features_psd.append(row)\nfeatures_psd = [row[:4] + row[5:] for row in features_psd]\n \nprint (features_psd)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n \ndf = pd.DataFrame(features_psd, columns=[  \"var_h\",\"mean_h\",\"S_D_h\",\"energy_h\",\"var_v\" , \"mean_v\",\"S_D_v\",\"energy_v\", \"label_y\"])\n\n \ndf.to_excel(\"Features_of_psd.xlsx\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the dataset\ndata = pd.read_excel('/kaggle/working/Features_of_psd.xlsx')\n\n# Split features and target variable\nX = data.drop('label_y', axis=1)\n \ny = data['label_y']\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n\n# Feature scaling\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Initialize SVM model\nsvm_model = SVC(random_state=12)\n\n# Define hyperparameters grid for tuning\nparam_grid = {\n    'C': [0.1, 1, 10, 100],  # Regularization parameter\n    'gamma': [0.1, 0.01, 0.001],  # Kernel coefficient for 'rbf', 'poly', 'sigmoid'\n    'kernel': ['linear', 'rbf', 'poly', 'sigmoid']\n}\n\n# Perform grid search to find the best hyperparameters\ngrid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\ngrid_search.fit(X_train_scaled, y_train)\n\n# Get the best hyperparameters\nbest_params = grid_search.best_params_\nprint(\"Best Hyperparameters:\", best_params)\n\n# Initialize SVM model with best hyperparameters\nbest_svm_model = SVC(**best_params, random_state=12)\n\n# Train the model with the best hyperparameters\nbest_svm_model.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = best_svm_model.predict(X_test_scaled)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)\n\n# Classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\n","metadata":{},"execution_count":null,"outputs":[]}]}